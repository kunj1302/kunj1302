# ðŸ”¥ Hi, I'm Kunj Golwala, a robotics enthusiast !!
Check out my [Portfolio Website](https://kunj1302.github.io/)

ðŸ‘¾ Iâ€™m interested in ... Mobile Robotics, Autonomous Driving, Robot Learning, and Computer Vision  
ðŸ›  Iâ€™m currently pursuing a Master's in Robotics at the University of Maryland, College Park  
ðŸ¤ Iâ€™m looking to collaborate on ... projects in AI, robotics, and embodied intelligence  

ðŸŒŸ I have worked at ...  
- **GAMMA Lab (UMD)** â€” Research Assistant, working on perception, behavior planning, and navigation for curbside autonomous robots using camera + LiDAR, MPPI planners, SLAM, and ROS 2  
- **Symbotic LLC (Ex-Perception Intern)** â€” Built and deployed vision transformerâ€“based perception systems for warehouse AMRs, optimized ROS 2 pipelines on Jetson with TensorRT  

ðŸ“¬ How to reach me ... **kunjgolwala13@gmail.com** | **kgolwala@umd.edu**

ðŸŽ¥ See my latest work in robotics here ->  
[TMI: OpenVLA Fine-Tuning](https://github.com/kunj13/openvla-tmi) | [Frenet Trajectory Planner](https://github.com/kunj13/frenet-planner) | [VisionNav](https://github.com/kunj13/vision-nav) | [Human-Following Robot](https://github.com/kunj13/Human-Following-Robot)

<p align="left">
  <img src="https://komarev.com/ghpvc/?username=kunj1302&label=Profile%20views&color=0e75b6&style=flat" alt="kunj1302" />
</p>

<a href="https://www.linkedin.com/in/kunj-golwala/">
  <img src="https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white">
</a>
<a href="https://github.com/kunj1302">
  <img src="https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white">
</a>

---

<p>
  <img align="left"
       src="https://github-readme-stats-sigma-five.vercel.app/api/top-langs?username=kunj1302&show_icons=true&locale=en&layout=compact"
       alt="kunj1302" />
</p>

<h3 align="left">Languages and Tools:</h3>
<p align="left"> 
  <a href="https://www.ros.org/" target="_blank">
    <img src="https://upload.wikimedia.org/wikipedia/commons/b/bb/Ros_logo.svg" alt="ROS" width="70" height="40"/> 
  </a> 
  <a href="https://gazebosim.org/" target="_blank">
    <img src="https://classic.gazebosim.org/assets/logos/gazebo_vert_pos-faad8cc37ab336f850e549077ef5831e5098034532113b06328dfd70355fb8f7.svg" alt="Gazebo" width="60" height="50"/> 
  </a> 
  <a href="https://opencv.org/" target="_blank">
    <img src="https://www.vectorlogo.zone/logos/opencv/opencv-icon.svg" width="40" height="40"/>
  </a>
  <a href="https://www.python.org" target="_blank">
    <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg" width="40" height="40"/>
  </a>
  <a href="https://git-scm.com/" target="_blank">
    <img src="https://www.vectorlogo.zone/logos/git-scm/git-scm-icon.svg" width="40" height="40"/>
  </a>
  <a href="https://www.docker.com/" target="_blank">
    <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/docker/docker-original-wordmark.svg" width="40" height="40"/>
  </a>
  <a href="https://www.linux.org/" target="_blank">
    <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/linux/linux-original.svg" width="40" height="40"/>
  </a>
  <a href="https://www.mathworks.com/products/matlab.html" target="_blank">
    <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/21/Matlab_Logo.png/667px-Matlab_Logo.png" width="40" height="40"/>
  </a>
  <a href="https://www.tensorflow.org/" target="_blank">
    <img src="https://www.vectorlogo.zone/logos/tensorflow/tensorflow-icon.svg" width="40" height="40"/>
  </a>
  <a href="https://pytorch.org/" target="_blank">
    <img src="https://www.vectorlogo.zone/logos/pytorch/pytorch-icon.svg" width="40" height="40"/>
  </a>
</p>

<p align="left">
  <a href="https://github.com/ryo-ma/github-profile-trophy">
    <img src="https://github-profile-trophy.vercel.app/?username=kunj1302" />
  </a>
</p>

---

## ðŸ”§ Projects and Research

- **TMI (Too Much Info): OpenVLA Fine-Tuning**  
  ðŸ”¹ Fine-tuned OpenVLA using behavior cloning on LIBERO (MuJoCo) with vision + language-conditioned actions  
  ðŸ”¹ Improved manipulation success by **35%** using LoRA fine-tuning and LLM-based instruction filtering  

- **Frenet Optimal Trajectory Planner**  
  ðŸ”¹ Implemented a Frenet-frame planner for lane keeping, lane changes, and vehicle following in CARLA  
  ðŸ”¹ Generated smooth trajectories using quintic polynomials with feasibility checks on curvature and jerk  

- **VisionNav: Autonomous Navigation System**  
  ðŸ”¹ Built a ROS 2 vision-based navigation stack with ArUco markers and EKF sensor fusion  
  ðŸ”¹ Integrated LiDAR (LIO-SAM), VIO, and optical-flow obstacle detection for real-time autonomy  

- **AI-Powered Human-Following Robot**  
  ðŸ”¹ Developed a ROS 2 human-following pipeline using camera-based tracking and SLAM  
  ðŸ”¹ Integrated ORB-SLAM, ICP scan matching, and potential-field obstacle avoidance  

---

## ðŸŽ¯ Goals
- To contribute to impactful projects in **autonomous systems** and **robot learning**  
- To bridge **classical robotics** and **foundation models** for real-world deployment  

---

Thanks for stopping by! Feel free to reach out or collaborate! ðŸ˜Š
